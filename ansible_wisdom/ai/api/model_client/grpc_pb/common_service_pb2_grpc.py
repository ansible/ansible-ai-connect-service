# Generated by the gRPC Python protocol compiler plugin. DO NOT EDIT!
"""Client and server classes corresponding to protobuf-defined services."""
import grpc

from . import category_types_pb2 as category__types__pb2
from . import classification_types_pb2 as classification__types__pb2
from . import common_service_pb2 as common__service__pb2
from . import concept_types_pb2 as concept__types__pb2
from . import data_model_pb2 as data__model__pb2
from . import emotion_types_pb2 as emotion__types__pb2
from . import entity_types_pb2 as entity__types__pb2
from . import keyword_types_pb2 as keyword__types__pb2
from . import lang_detect_types_pb2 as lang__detect__types__pb2
from . import nounphrases_types_pb2 as nounphrases__types__pb2
from . import relation_types_pb2 as relation__types__pb2
from . import rules_types_pb2 as rules__types__pb2
from . import sentiment_types_pb2 as sentiment__types__pb2
from . import syntax_types_pb2 as syntax__types__pb2
from . import target_mention_types_pb2 as target__mention__types__pb2
from . import topic_types_pb2 as topic__types__pb2


class CoreAnsibleWisdomExtServiceStub(object):
    """Missing associated documentation comment in .proto file."""

    def __init__(self, channel):
        """Constructor.

        Args:
            channel: A grpc.Channel.
        """
        self.ClassificationPredict = channel.unary_unary(
                '/watson.runtime.core_ansible_wisdom_ext.v0.CoreAnsibleWisdomExtService/ClassificationPredict',
                request_serializer=common__service__pb2.ClassificationRequest.SerializeToString,
                response_deserializer=classification__types__pb2.ClassificationPrediction.FromString,
                )
        self.SyntaxPredict = channel.unary_unary(
                '/watson.runtime.core_ansible_wisdom_ext.v0.CoreAnsibleWisdomExtService/SyntaxPredict',
                request_serializer=common__service__pb2.SyntaxRequest.SerializeToString,
                response_deserializer=syntax__types__pb2.SyntaxPrediction.FromString,
                )
        self.EntityMentionsPredict = channel.unary_unary(
                '/watson.runtime.core_ansible_wisdom_ext.v0.CoreAnsibleWisdomExtService/EntityMentionsPredict',
                request_serializer=common__service__pb2.EntityMentionsRequest.SerializeToString,
                response_deserializer=entity__types__pb2.EntityMentionsPrediction.FromString,
                )
        self.LangDetectPredict = channel.unary_unary(
                '/watson.runtime.core_ansible_wisdom_ext.v0.CoreAnsibleWisdomExtService/LangDetectPredict',
                request_serializer=common__service__pb2.LangDetectRequest.SerializeToString,
                response_deserializer=lang__detect__types__pb2.LangDetectPrediction.FromString,
                )
        self.NounPhrasesPredict = channel.unary_unary(
                '/watson.runtime.core_ansible_wisdom_ext.v0.CoreAnsibleWisdomExtService/NounPhrasesPredict',
                request_serializer=common__service__pb2.NounPhrasesRequest.SerializeToString,
                response_deserializer=nounphrases__types__pb2.NounPhrasesPrediction.FromString,
                )
        self.TargetMentionsPredict = channel.unary_unary(
                '/watson.runtime.core_ansible_wisdom_ext.v0.CoreAnsibleWisdomExtService/TargetMentionsPredict',
                request_serializer=common__service__pb2.TargetMentionsRequest.SerializeToString,
                response_deserializer=target__mention__types__pb2.TargetMentionsPrediction.FromString,
                )
        self.DetagPredict = channel.unary_unary(
                '/watson.runtime.core_ansible_wisdom_ext.v0.CoreAnsibleWisdomExtService/DetagPredict',
                request_serializer=common__service__pb2.DetagRequest.SerializeToString,
                response_deserializer=syntax__types__pb2.DetagPrediction.FromString,
                )
        self.RulesPredict = channel.unary_unary(
                '/watson.runtime.core_ansible_wisdom_ext.v0.CoreAnsibleWisdomExtService/RulesPredict',
                request_serializer=common__service__pb2.RulesRequest.SerializeToString,
                response_deserializer=rules__types__pb2.RulesPrediction.FromString,
                )
        self.CategoriesPredict = channel.unary_unary(
                '/watson.runtime.core_ansible_wisdom_ext.v0.CoreAnsibleWisdomExtService/CategoriesPredict',
                request_serializer=common__service__pb2.CategoriesRequest.SerializeToString,
                response_deserializer=category__types__pb2.CategoriesPrediction.FromString,
                )
        self.ConceptsPredict = channel.unary_unary(
                '/watson.runtime.core_ansible_wisdom_ext.v0.CoreAnsibleWisdomExtService/ConceptsPredict',
                request_serializer=common__service__pb2.ConceptsRequest.SerializeToString,
                response_deserializer=concept__types__pb2.ConceptsPrediction.FromString,
                )
        self.EntitiesPredict = channel.unary_unary(
                '/watson.runtime.core_ansible_wisdom_ext.v0.CoreAnsibleWisdomExtService/EntitiesPredict',
                request_serializer=common__service__pb2.EntitiesRequest.SerializeToString,
                response_deserializer=entity__types__pb2.EntitiesPrediction.FromString,
                )
        self.EmotionPredict = channel.unary_unary(
                '/watson.runtime.core_ansible_wisdom_ext.v0.CoreAnsibleWisdomExtService/EmotionPredict',
                request_serializer=common__service__pb2.EmotionRequest.SerializeToString,
                response_deserializer=emotion__types__pb2.EmotionPrediction.FromString,
                )
        self.KeywordsPredict = channel.unary_unary(
                '/watson.runtime.core_ansible_wisdom_ext.v0.CoreAnsibleWisdomExtService/KeywordsPredict',
                request_serializer=common__service__pb2.KeywordsRequest.SerializeToString,
                response_deserializer=keyword__types__pb2.KeywordsPrediction.FromString,
                )
        self.RelationsPredict = channel.unary_unary(
                '/watson.runtime.core_ansible_wisdom_ext.v0.CoreAnsibleWisdomExtService/RelationsPredict',
                request_serializer=common__service__pb2.RelationsRequest.SerializeToString,
                response_deserializer=relation__types__pb2.RelationsPrediction.FromString,
                )
        self.SentimentPredict = channel.unary_unary(
                '/watson.runtime.core_ansible_wisdom_ext.v0.CoreAnsibleWisdomExtService/SentimentPredict',
                request_serializer=common__service__pb2.SentimentRequest.SerializeToString,
                response_deserializer=sentiment__types__pb2.SentimentPrediction.FromString,
                )
        self.TopicsPredict = channel.unary_unary(
                '/watson.runtime.core_ansible_wisdom_ext.v0.CoreAnsibleWisdomExtService/TopicsPredict',
                request_serializer=common__service__pb2.TopicsRequest.SerializeToString,
                response_deserializer=topic__types__pb2.TopicsPrediction.FromString,
                )
        self.AnsibleWisdomPredict = channel.unary_unary(
                '/watson.runtime.core_ansible_wisdom_ext.v0.CoreAnsibleWisdomExtService/AnsibleWisdomPredict',
                request_serializer=common__service__pb2.AnsibleWisdomRequest.SerializeToString,
                response_deserializer=data__model__pb2.AnsibleWisdomModelPrediction.FromString,
                )


class CoreAnsibleWisdomExtServiceServicer(object):
    """Missing associated documentation comment in .proto file."""

    def ClassificationPredict(self, request, context):
        """*

        This rpc supports 6 Modules: ['BERT', 'Transformer', 'UseSvm', 'GloveCNN', 'TFidfSvm', 'GenericEnsemble']



        BERT docstring:

        ----------------------------

        Runs the classifier on an string input and returns the predictions

        Args:

        raw_document: watson_nlp.data_model.RawDocument or str



        Returns:

        watson_nlp.data_model.ClassificationPrediction

        The predicted class label (int), confidence (float)

        and scores (list(float)) for each of the M classes

        ----------------------------



        Transformer docstring:

        ----------------------------

        Runs the classifier on an string input and returns the predictions

        Args:

        raw_document: watson_nlp.data_model.RawDocument or str



        Returns:

        watson_nlp.data_model.ClassificationPrediction

        The predicted class label (int), confidence (float)

        and scores (list(float)) for each of the M classes

        ----------------------------



        UseSvm docstring:

        ----------------------------

        Runs the classifier algorithm on the text and returns the predictions



        Args:

        raw_document: str | watson_nlp.data_model.RawDocument

        The raw_document in str or dm.RawDocument format that needs to be classified.

        the model will only predict when either raw_document or syntax_prediction is passed.

        syntax_prediction: SyntaxPrediction

        The text in the dm.SyntaxPrediciton format that needs to be classified.

        the model will only predict when either raw_document or syntax_prediction is passed.



        Returns:

        watson_nlp.data_model.ClassificationPrediction:

        The predicted class label (str), and scores (float) for each of the M classes

        ----------------------------



        GloveCNN docstring:

        ----------------------------

        Runs the classifier algorithm on the text and returns the predictions



        Args:

        raw_document: str | watson_nlp.data_model.RawDocument

        The raw_document in str or dm.RawDocument format that needs to be classified.

        the model will only predict when either raw_document or syntax_prediction is passed.

        syntax_prediction: SyntaxPrediction

        The text in the dm.SyntaxPrediciton format that needs to be classified.

        the model will only predict when either raw_document or syntax_prediction is passed.



        Returns:

        watson_nlp.data_model.ClassificationPrediction:

        The predicted class label (str), and scores (float) for each of the M classes

        ----------------------------



        TFidfSvm docstring:

        ----------------------------

        Runs the classifier algorithm on the text and returns the predictions



        Args:

        raw_document: str | watson_nlp.data_model.RawDocument

        The raw_document in str or dm.RawDocument format that needs to be classified.

        the model will only predict when either raw_document or syntax_prediction is passed.

        syntax_prediction: SyntaxPrediction

        The text in the dm.SyntaxPrediciton format that needs to be classified.

        the model will only predict when either raw_document or syntax_prediction is passed.



        Returns:

        watson_nlp.data_model.ClassificationPrediction:

        The predicted class label (str), and scores (float) for each of the M classes

        ----------------------------



        GenericEnsemble docstring:

        ----------------------------

        Runs the classifier algorithm on the text and returns the predictions



        Args:

        raw_document: str | RawDocument

        The raw_document that needs to be classified

        if_multithread: bool

        The flag to specify whether the base classifier's prediction will run in parallelism



        Returns:

        watson_nlp.data_model.ClassificationPrediction: The predicted class label (str),

        and scores (float) for each of the M classes

        ----------------------------


        """
        context.set_code(grpc.StatusCode.UNIMPLEMENTED)
        context.set_details('Method not implemented!')
        raise NotImplementedError('Method not implemented!')

    def SyntaxPredict(self, request, context):
        """*

        This rpc supports 1 Modules: ['IzumoTextProcessing']



        IzumoTextProcessing docstring:

        ----------------------------

        Run IzumoTextProcessing on an input document or text string.



        Args:

        text:  watson_nlp.data_model.RawDocument or str

        Input document for which syntax analysis will be created.

        parsers:  list(str), list(data_model.enums.SyntaxParser) or data_model.SyntaxParserSpec

        Parsers used to construct syntax annotations.  Can be any of the values in the

        data_model.enums.SyntaxParser enum or else a data_model.SyntaxParserSpec or a list

        containing any of the following strings: 'token', 'sentence', 'lemma',

        'part_of_speech', 'dependency'



        Returns:

        watson_nlp.data_model.SyntaxPrediction

        SyntaxPrediction data model that contains the tokenization output.



        Notes:

        Some syntax parsers generate others as an intermediate step and will result in those

        syntax annotations being included.  For example, if you specify 'part_of_speech' then

        'token' will also be produced because tokenization is required to generate parts of

        speech.  In order to ensure that you are getting the correct annotations, however, it is

        recommended that you explicitly specify all desired syntax annotations.

        ----------------------------


        """
        context.set_code(grpc.StatusCode.UNIMPLEMENTED)
        context.set_details('Method not implemented!')
        raise NotImplementedError('Method not implemented!')

    def EntityMentionsPredict(self, request, context):
        """*

        This rpc supports 5 Modules: ['RBR', 'BERT', 'BiLSTM', 'SIRE', 'Transformer']



        RBR docstring:

        ----------------------------

        Run RBR mentions model on a given text and return predicted mentions.



        Args:

        raw_document:  watson_nlp.data_model.RawDocument or str

        Input document for which mentions will be extracted.

        language_code: str

        Language code corresponding to the text of the raw_document. By default

        this value will be None. If the model config doesn't include a language code, then

        this value will be used by RBR engine during runtime. If both language_code

        parameter and model language in model's config file exists, an error

        will be thrown by the run method.



        Returns:

        watson_nlp.data_model.EntityMentionsPrediction

        EntityMentionsPrediction with list of mentions which have information including

        mention span, type, text.

        ----------------------------



        BERT docstring:

        ----------------------------

        Extract entity mentions from a given raw document and language code. The syntax model is

        selected based on the language code and that yields a watson_nlp.data_model.SyntaxPrediction.

        The syntax analysis is then used by the BERT mentions model to yield

        watson_nlp.data_model.EntityMentionsPrediction



        Args:

        raw_document: watson_nlp.data_model.RawDocument or str

        Raw text of the document

        language_code: str

        Language code corresponding to the text of the raw_document



        Returns:

        watson_nlp.data_model.EntityMentionsPrediction

        The predicted entity mentions extracted from the given syntax analysis.

        ----------------------------



        BiLSTM docstring:

        ----------------------------

        Extract entity mentions from a given raw document. The instance's syntax model yields

        a watson_nlp.data_model.SyntaxPrediction which is then used by the mentions model to yield

        watson_nlp.data_model.EntityMentionsPrediction



        Args:

        raw_document: watson_nlp.data_model.RawDocument or str

        Raw text of the document



        Returns:

        watson_nlp.data_model.EntityMentionsPrediction

        The predicted entity mentions extracted from the given syntax analysis.

        ----------------------------



        SIRE docstring:

        ----------------------------

        Extract entity mentions from a given raw document. The instance's syntax model yields

        a watson_nlp.data_model.SyntaxPrediction which is then used by the mentions model to yield

        watson_nlp.data_model.EntityMentionsPrediction



        Args:

        raw_document: watson_nlp.data_model.RawDocument or str

        Raw text of the document



        Returns:

        watson_nlp.data_model.EntityMentionsPrediction

        EntityMentionsPrediction with list of mentions which have information including

        mention span, type, text.

        ----------------------------



        Transformer docstring:

        ----------------------------

        Extract entity mentions from a given raw document and language code. The syntax model is

        selected based on the language code and that yields a watson_nlp.data_model.SyntaxPrediction.

        The syntax analysis is then used by the BERT mentions model to yield

        watson_nlp.data_model.EntityMentionsPrediction



        Args:

        raw_document: watson_nlp.data_model.RawDocument or str

        Raw text of the document

        language_code: str

        Language code corresponding to the text of the raw_document



        Returns:

        watson_nlp.data_model.EntityMentionsPrediction

        The predicted entity mentions extracted from the given syntax analysis.

        ----------------------------


        """
        context.set_code(grpc.StatusCode.UNIMPLEMENTED)
        context.set_details('Method not implemented!')
        raise NotImplementedError('Method not implemented!')

    def LangDetectPredict(self, request, context):
        """*

        This rpc supports 1 Modules: ['Izumo']



        Izumo docstring:

        ----------------------------

        Run Language detection on a given text and return predicted language.



        Args:

        raw_document:  watson_nlp.data_model.RawDocument or str

        Input document for which language will be identified.



        Returns:

        watson_nlp.data_model.LangDetectPrediction

        LangDetectPrediction with the enum of the language predicted

        ----------------------------


        """
        context.set_code(grpc.StatusCode.UNIMPLEMENTED)
        context.set_details('Method not implemented!')
        raise NotImplementedError('Method not implemented!')

    def NounPhrasesPredict(self, request, context):
        """*

        This rpc supports 1 Modules: ['RBR']



        RBR docstring:

        ----------------------------

        Run Noun phrases model on a given text and return predicted noun phrases.



        Args:

        raw_document:  watson_nlp.data_model.RawDocument or str

        Input document for which noun phrases will be extracted.



        Returns:

        watson_nlp.data_model.NounPhrasesPrediction

        NounPhrasesPrediction with list of noun phrases which have information including

        noun phrase span, type, text.

        ----------------------------


        """
        context.set_code(grpc.StatusCode.UNIMPLEMENTED)
        context.set_details('Method not implemented!')
        raise NotImplementedError('Method not implemented!')

    def TargetMentionsPredict(self, request, context):
        """*

        This rpc supports 1 Modules: ['WordRegex']



        WordRegex docstring:

        ----------------------------

        Extract the mentions for the given set of targets.



        Args:

        raw_document:  watson_nlp.data_model.RawDocument or str

        The raw document holding the input text.

        targets:  dm.TargetPhrases or list(str)

        The list of target phrases to extract mentions for.



        Returns:

        dm.TargetMentionsPrediction

        The extracted mention offset list for each target.

        ----------------------------


        """
        context.set_code(grpc.StatusCode.UNIMPLEMENTED)
        context.set_details('Method not implemented!')
        raise NotImplementedError('Method not implemented!')

    def DetagPredict(self, request, context):
        """*

        This rpc supports 1 Modules: ['RBR']



        RBR docstring:

        ----------------------------

        Detag an HTML document text to obtain its detagged plain text representation.



        Args:

        raw_document: dm.RawDocument

        HTML encoded string. e.g. <html><body>text</body></html>



        Returns:

        watson_nlp.data_model.DetagPrediction

        The DetagPrediction object with original html_doc, detagged text and set of offsets.

        ----------------------------


        """
        context.set_code(grpc.StatusCode.UNIMPLEMENTED)
        context.set_details('Method not implemented!')
        raise NotImplementedError('Method not implemented!')

    def RulesPredict(self, request, context):
        """*

        This rpc supports 1 Modules: ['RBRGeneric']



        RBRGeneric docstring:

        ----------------------------

        Run RBR engine on the given document with the loaded model.



        Args:

        raw_document:  watson_nlp.data_model.RawDocument or str

        Input document for which mentions will be extracted.



        Returns:

        watson_nlp.data_model.RulesPrediction

        RulesPrediction with list of views which internally have a map of matching

        properties.

        ----------------------------


        """
        context.set_code(grpc.StatusCode.UNIMPLEMENTED)
        context.set_details('Method not implemented!')
        raise NotImplementedError('Method not implemented!')

    def CategoriesPredict(self, request, context):
        """*

        This rpc supports 1 Modules: ['ESAHierarchical']



        ESAHierarchical docstring:

        ----------------------------

        Perform categories predictions on an input document, with optional explanations



        Args:

        raw_document: watson_nlp.data_model.RawDocument

        The input document on which to perform categories predictions

        explanation: Boolean

        Boolean flag indicating whether or not explanations should be computed and returned

        limit:  int

        The maximum number of predicted categories.  If not specified then the

        limit on the number of predicted categories defaults to 3



        Returns:

        watson_nlp.data_model.CategoriesPrediction

        The result of categories prediction with optional explanations.

        ----------------------------


        """
        context.set_code(grpc.StatusCode.UNIMPLEMENTED)
        context.set_details('Method not implemented!')
        raise NotImplementedError('Method not implemented!')

    def ConceptsPredict(self, request, context):
        """*

        This rpc supports 1 Modules: ['ConceptsWorkflow']



        ConceptsWorkflow docstring:

        ----------------------------



        Args:

        raw_document: watson_nlp.data_model.RawDocument or str

        Raw text of the document

        limit: int

        Maximum number of concepts to return, default is 50

        Returns:

        watson_nlp.data_model.concepts.ConceptsPrediction

        Concepts Prediction data model

        ----------------------------


        """
        context.set_code(grpc.StatusCode.UNIMPLEMENTED)
        context.set_details('Method not implemented!')
        raise NotImplementedError('Method not implemented!')

    def EntitiesPredict(self, request, context):
        """*

        This rpc supports 1 Modules: ['SIRE']



        SIRE docstring:

        ----------------------------

        Extract entities from a given raw document. The instance's syntax model yields

        a watson_nlp.data_model.SyntaxPrediction which is then used by the mentions model to yield

        watson_nlp.data_model.EntityMentionsPrediction which is finally used by the entities model to yield

        watson_nlp.data_model.EntitiesPrediction

        Args:

        raw_document: watson_nlp.data_model.RawDocument or str

        Raw text of the document



        Returns:

        watson_nlp.data_model.EntitiesPrediction

        EntitiesPrediction with list of entities which have information including

        mention span, type, text.

        ----------------------------


        """
        context.set_code(grpc.StatusCode.UNIMPLEMENTED)
        context.set_details('Method not implemented!')
        raise NotImplementedError('Method not implemented!')

    def EmotionPredict(self, request, context):
        """*

        This rpc supports 1 Modules: ['AggregatedClassificationEnsemble']



        AggregatedClassificationEnsemble docstring:

        ----------------------------



        Args:

        raw_document: watson_nlp.data_model.RawDocument or str

        Raw text of the document

        document_emotion: bool

        Whether to perform emotion classification at the document level or not. Default is True.

        target_mentions: watson_nlp.data_model.TargetMentionsPrediction or list(list(tuple))

        An optional collection of span-based targets on which to perform targeted analysis,

        likely derived from the output of another block

        E.g. [[(0, 1), (14, 15)], [(16, 17), (29, 30)]]

        target_phrases: watson_nlp.data_model.TargetPhrases or list(str)

        An optional list of target strings or collection of text-based targets

        that will typically be provided by the user of this workflow directly.

        Such target strings will be converted to target mentions as part of this workflow.

        Returns:

        watson_nlp.data_model.emotion.EmotionPrediction

        Emotion Prediction data model for a document and zero or more targets,

        calculated by averaging the emotion scores per sentence.

        ----------------------------


        """
        context.set_code(grpc.StatusCode.UNIMPLEMENTED)
        context.set_details('Method not implemented!')
        raise NotImplementedError('Method not implemented!')

    def KeywordsPredict(self, request, context):
        """*

        This rpc supports 1 Modules: ['TextRank']



        TextRank docstring:

        ----------------------------

        Perform keywords extraction on an input document



        Args:

        raw_document: watson_nlp.data_model.RawDocument

        The input document on which to perform keywords extraction

        limit:  None or int

        The maximum number of predicted keywords.  If not specified then the

        limit on the number of predicted keywords defaults to None



        Returns:

        watson_nlp.data_model.KeywordsPrediction

        The result of keywords extraction.

        ----------------------------


        """
        context.set_code(grpc.StatusCode.UNIMPLEMENTED)
        context.set_details('Method not implemented!')
        raise NotImplementedError('Method not implemented!')

    def RelationsPredict(self, request, context):
        """*

        This rpc supports 2 Modules: ['SIRE', 'Transformer']



        SIRE docstring:

        ----------------------------

        Extract relation mentions from a given raw document. The instance's syntax model yields

        a watson_nlp.data_model.SyntaxPrediction which is then used by the mentions model to yield

        watson_nlp.data_model.EntityMentionsPrediction and the used by the transformer model to yield

        watson_nlp.data_model.RelationsPrediction.

        Args:

        raw_document: watson_nlp.data_model.RawDocument or str

        Raw text of the document.

        Returns:

        watson_nlp.data_model.RelationsPrediction

        RelationsPrediction with list of relations which have information including

        mentions, entities, text.

        ----------------------------



        Transformer docstring:

        ----------------------------

        Extract relation mentions from a given raw document. The instance's syntax model yields

        a watson_nlp.data_model.SyntaxPrediction which is then used by the mentions model to yield

        watson_nlp.data_model.EntityMentionsPrediction and the used by the transformer model to yield

        watson_nlp.data_model.RelationsPrediction.

        Args:

        raw_document: watson_nlp.data_model.RawDocument or str

        Raw text of the document.

        Returns:

        watson_nlp.data_model.RelationsPrediction

        RelationsPrediction with list of relations which have information including

        mentions, entities, text.

        ----------------------------


        """
        context.set_code(grpc.StatusCode.UNIMPLEMENTED)
        context.set_details('Method not implemented!')
        raise NotImplementedError('Method not implemented!')

    def SentimentPredict(self, request, context):
        """*

        This rpc supports 1 Modules: ['AggregatedSentiment']



        AggregatedSentiment docstring:

        ----------------------------

        Perform sentiment analysis on an input document, with Optional targets.



        Args:

        raw_document: dm.RawDocument | str

        The input document on which to perform sentiment analysis

        language_code: str, Optional

        An optional language code for the input text, required if the model is multi-lingual

        document_sentiment: bool, Optional

        Whether to aggregate the document sentiment

        target_mentions: watson_nlp.data_model.TargetMentionsPrediction, Optional

        An optional collection of span-based targets on which to perform targeted analysis,

        likely derived from the output of another block

        target_phrases: watson_nlp.data_model.TargetPhrases | List[str], Optional

        An optional collection of text-based targets on which to perform targeted analysis

        show_neutral_scores:  bool, Optional

        Return scores that would have been flattened to neutral/zero



        Returns:

        watson_nlp.data_model.SentimentPrediction

        The result of sentiment analysis, optionally including targeted sentiment



        Note: target_mentions can be created via helpers found in the TargetMentionsPrediction

        class (e.g., TargetMentionsPrediction.from_entities_prediction()), and are typically the

        result of spans generated as part of the output of other blocks (e.g., mention taggers).

        In contrast, target_phrases contains a collection of target strings that will typically be

        provided by the user of this workflow directly.  Such target strings will be converted

        to target mentions as part of this workflow.

        ----------------------------


        """
        context.set_code(grpc.StatusCode.UNIMPLEMENTED)
        context.set_details('Method not implemented!')
        raise NotImplementedError('Method not implemented!')

    def TopicsPredict(self, request, context):
        """*

        This rpc supports 1 Modules: ['HierarchicalClustering']



        HierarchicalClustering docstring:

        ----------------------------

        Run a single document through the trained topic model. It is possible

        that no topic will be assigned to a document if it cannot assign

        a satisfactory cluster.



        Args:

        raw_document: watson_nlp.data_model.RawDocument or str

        Input document for which we would like to try to assign a topic.



        Returns:

        topics_prediction: data_model.TopicsPrediction.

        The predicted topic for the provided text document.

        ----------------------------


        """
        context.set_code(grpc.StatusCode.UNIMPLEMENTED)
        context.set_details('Method not implemented!')
        raise NotImplementedError('Method not implemented!')

    def AnsibleWisdomPredict(self, request, context):
        """*

        This rpc supports 1 Modules: ['AnsibleWisdomModel']



        AnsibleWisdomModel docstring:

        ----------------------------

        Run hugging face sentiment-analysis pipeline model on

        input raw data



        Args:

        prompt: str | Prompt

        Prompt for task to be performed

        raw_document: str | RawDocument

        The raw_document that needs to be classified

        Returns:

        watson_core_ansible_wisdom_ext.data_model.AnsibleWisdomModelPrediction: The predicted class label (str),

        and scores (float) for each of the sentiment classes

        ----------------------------


        """
        context.set_code(grpc.StatusCode.UNIMPLEMENTED)
        context.set_details('Method not implemented!')
        raise NotImplementedError('Method not implemented!')


def add_CoreAnsibleWisdomExtServiceServicer_to_server(servicer, server):
    rpc_method_handlers = {
            'ClassificationPredict': grpc.unary_unary_rpc_method_handler(
                    servicer.ClassificationPredict,
                    request_deserializer=common__service__pb2.ClassificationRequest.FromString,
                    response_serializer=classification__types__pb2.ClassificationPrediction.SerializeToString,
            ),
            'SyntaxPredict': grpc.unary_unary_rpc_method_handler(
                    servicer.SyntaxPredict,
                    request_deserializer=common__service__pb2.SyntaxRequest.FromString,
                    response_serializer=syntax__types__pb2.SyntaxPrediction.SerializeToString,
            ),
            'EntityMentionsPredict': grpc.unary_unary_rpc_method_handler(
                    servicer.EntityMentionsPredict,
                    request_deserializer=common__service__pb2.EntityMentionsRequest.FromString,
                    response_serializer=entity__types__pb2.EntityMentionsPrediction.SerializeToString,
            ),
            'LangDetectPredict': grpc.unary_unary_rpc_method_handler(
                    servicer.LangDetectPredict,
                    request_deserializer=common__service__pb2.LangDetectRequest.FromString,
                    response_serializer=lang__detect__types__pb2.LangDetectPrediction.SerializeToString,
            ),
            'NounPhrasesPredict': grpc.unary_unary_rpc_method_handler(
                    servicer.NounPhrasesPredict,
                    request_deserializer=common__service__pb2.NounPhrasesRequest.FromString,
                    response_serializer=nounphrases__types__pb2.NounPhrasesPrediction.SerializeToString,
            ),
            'TargetMentionsPredict': grpc.unary_unary_rpc_method_handler(
                    servicer.TargetMentionsPredict,
                    request_deserializer=common__service__pb2.TargetMentionsRequest.FromString,
                    response_serializer=target__mention__types__pb2.TargetMentionsPrediction.SerializeToString,
            ),
            'DetagPredict': grpc.unary_unary_rpc_method_handler(
                    servicer.DetagPredict,
                    request_deserializer=common__service__pb2.DetagRequest.FromString,
                    response_serializer=syntax__types__pb2.DetagPrediction.SerializeToString,
            ),
            'RulesPredict': grpc.unary_unary_rpc_method_handler(
                    servicer.RulesPredict,
                    request_deserializer=common__service__pb2.RulesRequest.FromString,
                    response_serializer=rules__types__pb2.RulesPrediction.SerializeToString,
            ),
            'CategoriesPredict': grpc.unary_unary_rpc_method_handler(
                    servicer.CategoriesPredict,
                    request_deserializer=common__service__pb2.CategoriesRequest.FromString,
                    response_serializer=category__types__pb2.CategoriesPrediction.SerializeToString,
            ),
            'ConceptsPredict': grpc.unary_unary_rpc_method_handler(
                    servicer.ConceptsPredict,
                    request_deserializer=common__service__pb2.ConceptsRequest.FromString,
                    response_serializer=concept__types__pb2.ConceptsPrediction.SerializeToString,
            ),
            'EntitiesPredict': grpc.unary_unary_rpc_method_handler(
                    servicer.EntitiesPredict,
                    request_deserializer=common__service__pb2.EntitiesRequest.FromString,
                    response_serializer=entity__types__pb2.EntitiesPrediction.SerializeToString,
            ),
            'EmotionPredict': grpc.unary_unary_rpc_method_handler(
                    servicer.EmotionPredict,
                    request_deserializer=common__service__pb2.EmotionRequest.FromString,
                    response_serializer=emotion__types__pb2.EmotionPrediction.SerializeToString,
            ),
            'KeywordsPredict': grpc.unary_unary_rpc_method_handler(
                    servicer.KeywordsPredict,
                    request_deserializer=common__service__pb2.KeywordsRequest.FromString,
                    response_serializer=keyword__types__pb2.KeywordsPrediction.SerializeToString,
            ),
            'RelationsPredict': grpc.unary_unary_rpc_method_handler(
                    servicer.RelationsPredict,
                    request_deserializer=common__service__pb2.RelationsRequest.FromString,
                    response_serializer=relation__types__pb2.RelationsPrediction.SerializeToString,
            ),
            'SentimentPredict': grpc.unary_unary_rpc_method_handler(
                    servicer.SentimentPredict,
                    request_deserializer=common__service__pb2.SentimentRequest.FromString,
                    response_serializer=sentiment__types__pb2.SentimentPrediction.SerializeToString,
            ),
            'TopicsPredict': grpc.unary_unary_rpc_method_handler(
                    servicer.TopicsPredict,
                    request_deserializer=common__service__pb2.TopicsRequest.FromString,
                    response_serializer=topic__types__pb2.TopicsPrediction.SerializeToString,
            ),
            'AnsibleWisdomPredict': grpc.unary_unary_rpc_method_handler(
                    servicer.AnsibleWisdomPredict,
                    request_deserializer=common__service__pb2.AnsibleWisdomRequest.FromString,
                    response_serializer=data__model__pb2.AnsibleWisdomModelPrediction.SerializeToString,
            ),
    }
    generic_handler = grpc.method_handlers_generic_handler(
            'watson.runtime.core_ansible_wisdom_ext.v0.CoreAnsibleWisdomExtService', rpc_method_handlers)
    server.add_generic_rpc_handlers((generic_handler,))


 # This class is part of an EXPERIMENTAL API.
class CoreAnsibleWisdomExtService(object):
    """Missing associated documentation comment in .proto file."""

    @staticmethod
    def ClassificationPredict(request,
            target,
            options=(),
            channel_credentials=None,
            call_credentials=None,
            insecure=False,
            compression=None,
            wait_for_ready=None,
            timeout=None,
            metadata=None):
        return grpc.experimental.unary_unary(request, target, '/watson.runtime.core_ansible_wisdom_ext.v0.CoreAnsibleWisdomExtService/ClassificationPredict',
            common__service__pb2.ClassificationRequest.SerializeToString,
            classification__types__pb2.ClassificationPrediction.FromString,
            options, channel_credentials,
            insecure, call_credentials, compression, wait_for_ready, timeout, metadata)

    @staticmethod
    def SyntaxPredict(request,
            target,
            options=(),
            channel_credentials=None,
            call_credentials=None,
            insecure=False,
            compression=None,
            wait_for_ready=None,
            timeout=None,
            metadata=None):
        return grpc.experimental.unary_unary(request, target, '/watson.runtime.core_ansible_wisdom_ext.v0.CoreAnsibleWisdomExtService/SyntaxPredict',
            common__service__pb2.SyntaxRequest.SerializeToString,
            syntax__types__pb2.SyntaxPrediction.FromString,
            options, channel_credentials,
            insecure, call_credentials, compression, wait_for_ready, timeout, metadata)

    @staticmethod
    def EntityMentionsPredict(request,
            target,
            options=(),
            channel_credentials=None,
            call_credentials=None,
            insecure=False,
            compression=None,
            wait_for_ready=None,
            timeout=None,
            metadata=None):
        return grpc.experimental.unary_unary(request, target, '/watson.runtime.core_ansible_wisdom_ext.v0.CoreAnsibleWisdomExtService/EntityMentionsPredict',
            common__service__pb2.EntityMentionsRequest.SerializeToString,
            entity__types__pb2.EntityMentionsPrediction.FromString,
            options, channel_credentials,
            insecure, call_credentials, compression, wait_for_ready, timeout, metadata)

    @staticmethod
    def LangDetectPredict(request,
            target,
            options=(),
            channel_credentials=None,
            call_credentials=None,
            insecure=False,
            compression=None,
            wait_for_ready=None,
            timeout=None,
            metadata=None):
        return grpc.experimental.unary_unary(request, target, '/watson.runtime.core_ansible_wisdom_ext.v0.CoreAnsibleWisdomExtService/LangDetectPredict',
            common__service__pb2.LangDetectRequest.SerializeToString,
            lang__detect__types__pb2.LangDetectPrediction.FromString,
            options, channel_credentials,
            insecure, call_credentials, compression, wait_for_ready, timeout, metadata)

    @staticmethod
    def NounPhrasesPredict(request,
            target,
            options=(),
            channel_credentials=None,
            call_credentials=None,
            insecure=False,
            compression=None,
            wait_for_ready=None,
            timeout=None,
            metadata=None):
        return grpc.experimental.unary_unary(request, target, '/watson.runtime.core_ansible_wisdom_ext.v0.CoreAnsibleWisdomExtService/NounPhrasesPredict',
            common__service__pb2.NounPhrasesRequest.SerializeToString,
            nounphrases__types__pb2.NounPhrasesPrediction.FromString,
            options, channel_credentials,
            insecure, call_credentials, compression, wait_for_ready, timeout, metadata)

    @staticmethod
    def TargetMentionsPredict(request,
            target,
            options=(),
            channel_credentials=None,
            call_credentials=None,
            insecure=False,
            compression=None,
            wait_for_ready=None,
            timeout=None,
            metadata=None):
        return grpc.experimental.unary_unary(request, target, '/watson.runtime.core_ansible_wisdom_ext.v0.CoreAnsibleWisdomExtService/TargetMentionsPredict',
            common__service__pb2.TargetMentionsRequest.SerializeToString,
            target__mention__types__pb2.TargetMentionsPrediction.FromString,
            options, channel_credentials,
            insecure, call_credentials, compression, wait_for_ready, timeout, metadata)

    @staticmethod
    def DetagPredict(request,
            target,
            options=(),
            channel_credentials=None,
            call_credentials=None,
            insecure=False,
            compression=None,
            wait_for_ready=None,
            timeout=None,
            metadata=None):
        return grpc.experimental.unary_unary(request, target, '/watson.runtime.core_ansible_wisdom_ext.v0.CoreAnsibleWisdomExtService/DetagPredict',
            common__service__pb2.DetagRequest.SerializeToString,
            syntax__types__pb2.DetagPrediction.FromString,
            options, channel_credentials,
            insecure, call_credentials, compression, wait_for_ready, timeout, metadata)

    @staticmethod
    def RulesPredict(request,
            target,
            options=(),
            channel_credentials=None,
            call_credentials=None,
            insecure=False,
            compression=None,
            wait_for_ready=None,
            timeout=None,
            metadata=None):
        return grpc.experimental.unary_unary(request, target, '/watson.runtime.core_ansible_wisdom_ext.v0.CoreAnsibleWisdomExtService/RulesPredict',
            common__service__pb2.RulesRequest.SerializeToString,
            rules__types__pb2.RulesPrediction.FromString,
            options, channel_credentials,
            insecure, call_credentials, compression, wait_for_ready, timeout, metadata)

    @staticmethod
    def CategoriesPredict(request,
            target,
            options=(),
            channel_credentials=None,
            call_credentials=None,
            insecure=False,
            compression=None,
            wait_for_ready=None,
            timeout=None,
            metadata=None):
        return grpc.experimental.unary_unary(request, target, '/watson.runtime.core_ansible_wisdom_ext.v0.CoreAnsibleWisdomExtService/CategoriesPredict',
            common__service__pb2.CategoriesRequest.SerializeToString,
            category__types__pb2.CategoriesPrediction.FromString,
            options, channel_credentials,
            insecure, call_credentials, compression, wait_for_ready, timeout, metadata)

    @staticmethod
    def ConceptsPredict(request,
            target,
            options=(),
            channel_credentials=None,
            call_credentials=None,
            insecure=False,
            compression=None,
            wait_for_ready=None,
            timeout=None,
            metadata=None):
        return grpc.experimental.unary_unary(request, target, '/watson.runtime.core_ansible_wisdom_ext.v0.CoreAnsibleWisdomExtService/ConceptsPredict',
            common__service__pb2.ConceptsRequest.SerializeToString,
            concept__types__pb2.ConceptsPrediction.FromString,
            options, channel_credentials,
            insecure, call_credentials, compression, wait_for_ready, timeout, metadata)

    @staticmethod
    def EntitiesPredict(request,
            target,
            options=(),
            channel_credentials=None,
            call_credentials=None,
            insecure=False,
            compression=None,
            wait_for_ready=None,
            timeout=None,
            metadata=None):
        return grpc.experimental.unary_unary(request, target, '/watson.runtime.core_ansible_wisdom_ext.v0.CoreAnsibleWisdomExtService/EntitiesPredict',
            common__service__pb2.EntitiesRequest.SerializeToString,
            entity__types__pb2.EntitiesPrediction.FromString,
            options, channel_credentials,
            insecure, call_credentials, compression, wait_for_ready, timeout, metadata)

    @staticmethod
    def EmotionPredict(request,
            target,
            options=(),
            channel_credentials=None,
            call_credentials=None,
            insecure=False,
            compression=None,
            wait_for_ready=None,
            timeout=None,
            metadata=None):
        return grpc.experimental.unary_unary(request, target, '/watson.runtime.core_ansible_wisdom_ext.v0.CoreAnsibleWisdomExtService/EmotionPredict',
            common__service__pb2.EmotionRequest.SerializeToString,
            emotion__types__pb2.EmotionPrediction.FromString,
            options, channel_credentials,
            insecure, call_credentials, compression, wait_for_ready, timeout, metadata)

    @staticmethod
    def KeywordsPredict(request,
            target,
            options=(),
            channel_credentials=None,
            call_credentials=None,
            insecure=False,
            compression=None,
            wait_for_ready=None,
            timeout=None,
            metadata=None):
        return grpc.experimental.unary_unary(request, target, '/watson.runtime.core_ansible_wisdom_ext.v0.CoreAnsibleWisdomExtService/KeywordsPredict',
            common__service__pb2.KeywordsRequest.SerializeToString,
            keyword__types__pb2.KeywordsPrediction.FromString,
            options, channel_credentials,
            insecure, call_credentials, compression, wait_for_ready, timeout, metadata)

    @staticmethod
    def RelationsPredict(request,
            target,
            options=(),
            channel_credentials=None,
            call_credentials=None,
            insecure=False,
            compression=None,
            wait_for_ready=None,
            timeout=None,
            metadata=None):
        return grpc.experimental.unary_unary(request, target, '/watson.runtime.core_ansible_wisdom_ext.v0.CoreAnsibleWisdomExtService/RelationsPredict',
            common__service__pb2.RelationsRequest.SerializeToString,
            relation__types__pb2.RelationsPrediction.FromString,
            options, channel_credentials,
            insecure, call_credentials, compression, wait_for_ready, timeout, metadata)

    @staticmethod
    def SentimentPredict(request,
            target,
            options=(),
            channel_credentials=None,
            call_credentials=None,
            insecure=False,
            compression=None,
            wait_for_ready=None,
            timeout=None,
            metadata=None):
        return grpc.experimental.unary_unary(request, target, '/watson.runtime.core_ansible_wisdom_ext.v0.CoreAnsibleWisdomExtService/SentimentPredict',
            common__service__pb2.SentimentRequest.SerializeToString,
            sentiment__types__pb2.SentimentPrediction.FromString,
            options, channel_credentials,
            insecure, call_credentials, compression, wait_for_ready, timeout, metadata)

    @staticmethod
    def TopicsPredict(request,
            target,
            options=(),
            channel_credentials=None,
            call_credentials=None,
            insecure=False,
            compression=None,
            wait_for_ready=None,
            timeout=None,
            metadata=None):
        return grpc.experimental.unary_unary(request, target, '/watson.runtime.core_ansible_wisdom_ext.v0.CoreAnsibleWisdomExtService/TopicsPredict',
            common__service__pb2.TopicsRequest.SerializeToString,
            topic__types__pb2.TopicsPrediction.FromString,
            options, channel_credentials,
            insecure, call_credentials, compression, wait_for_ready, timeout, metadata)

    @staticmethod
    def AnsibleWisdomPredict(request,
            target,
            options=(),
            channel_credentials=None,
            call_credentials=None,
            insecure=False,
            compression=None,
            wait_for_ready=None,
            timeout=None,
            metadata=None):
        return grpc.experimental.unary_unary(request, target, '/watson.runtime.core_ansible_wisdom_ext.v0.CoreAnsibleWisdomExtService/AnsibleWisdomPredict',
            common__service__pb2.AnsibleWisdomRequest.SerializeToString,
            data__model__pb2.AnsibleWisdomModelPrediction.FromString,
            options, channel_credentials,
            insecure, call_credentials, compression, wait_for_ready, timeout, metadata)
